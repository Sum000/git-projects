{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eba358c3-da00-49d0-8c96-6a62e8ca984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc8fe824-4198-42ea-a730-fb11c5e7d18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = 'holmes.txt'\n",
    "with open(data_file, 'r', encoding='utf-8') as infile:\n",
    "    data = infile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23ea52ad-774f-4192-89fa-f05dd84ee481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"*Project Gutenberg's Etext of Tom Swift And His Submarine Boat*\\n\\n#4 in the Victor Appleton's Tom Swi\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e23ae073-777e-45e1-ab84-ad6ceb1834d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:200000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85251a53-c899-432c-b381-87e678a45438",
   "metadata": {},
   "source": [
    "PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92d05e0e-727c-4799-b120-18d0d64f012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_characters(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "                               u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "                               u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                               u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                               u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "                               u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                               u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                               u\"\\U000024C2-\\U0001F251\" \n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f6492ed-ce03-4905-ab11-56f1c496358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data) -> 'list':\n",
    "    sentences = data.split('\\n')\n",
    "    for i in range(len(sentences)):\n",
    "        sentences[i] = remove_characters(sentences[i])\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    sentences = [s for s in sentences if len(s) > 0]\n",
    "    tokenized = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.lower()\n",
    "        tokenized.append(sentence)\n",
    "    return tokenized\n",
    "    \n",
    "tokenized_sentences = preprocessing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8b29c04-be3f-40f4-9236-77bbbe4ceb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token='<oov>')\n",
    "tokenizer.fit_on_texts(tokenized_sentences)\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a31086f5-151f-4753-b19e-34e83d6e866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in tokenized_sentences:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i + 1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab2265c8-b4a3-4a0b-a738-baae4297c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7590029-8ee2-4f05-9db9-8e4356a1cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "450b63d0-dc79-43ff-b780-7ba7f12dc5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_temp, X_val_test, y_train_temp, y_val_test = train_test_split(X, ys, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed4461e-7c11-4392-817e-fb34974379fc",
   "metadata": {},
   "source": [
    "TRAINING USING LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc32aa1c-d54b-4d61-bb23-ba4168fea8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 36ms/step - accuracy: 0.0816 - loss: 6.4157 - val_accuracy: 0.1219 - val_loss: 5.6868\n",
      "Epoch 2/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 37ms/step - accuracy: 0.1493 - loss: 5.1244 - val_accuracy: 0.1408 - val_loss: 5.6593\n",
      "Epoch 3/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 39ms/step - accuracy: 0.1885 - loss: 4.4672 - val_accuracy: 0.1427 - val_loss: 5.8203\n",
      "Epoch 4/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 41ms/step - accuracy: 0.2326 - loss: 3.8947 - val_accuracy: 0.1380 - val_loss: 6.1859\n",
      "Epoch 5/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.2553 - loss: 3.7844 - val_accuracy: 0.1352 - val_loss: 6.3968\n",
      "Epoch 6/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 42ms/step - accuracy: 0.3272 - loss: 3.0706 - val_accuracy: 0.1358 - val_loss: 6.6664\n",
      "Epoch 7/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.3703 - loss: 2.7255 - val_accuracy: 0.1320 - val_loss: 6.9385\n",
      "Epoch 8/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 36ms/step - accuracy: 0.4135 - loss: 2.4897 - val_accuracy: 0.1342 - val_loss: 7.2052\n",
      "Epoch 9/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.4485 - loss: 2.2719 - val_accuracy: 0.1238 - val_loss: 7.4411\n",
      "Epoch 10/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.4673 - loss: 2.1532 - val_accuracy: 0.1219 - val_loss: 7.6899\n",
      "Epoch 11/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.4882 - loss: 2.0669 - val_accuracy: 0.1144 - val_loss: 7.9167\n",
      "Epoch 12/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 39ms/step - accuracy: 0.5145 - loss: 1.9386 - val_accuracy: 0.1216 - val_loss: 8.1655\n",
      "Epoch 13/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.5305 - loss: 1.8663 - val_accuracy: 0.1128 - val_loss: 8.3431\n",
      "Epoch 14/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 37ms/step - accuracy: 0.5362 - loss: 1.8124 - val_accuracy: 0.1128 - val_loss: 8.4877\n",
      "Epoch 15/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 37ms/step - accuracy: 0.5513 - loss: 1.7349 - val_accuracy: 0.1191 - val_loss: 8.7756\n",
      "Epoch 16/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 56ms/step - accuracy: 0.5561 - loss: 1.7134 - val_accuracy: 0.1175 - val_loss: 8.9629\n",
      "Epoch 17/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 75ms/step - accuracy: 0.5602 - loss: 1.6964 - val_accuracy: 0.1175 - val_loss: 9.0231\n",
      "Epoch 18/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.5615 - loss: 1.6775 - val_accuracy: 0.1096 - val_loss: 9.2828\n",
      "Epoch 19/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 63ms/step - accuracy: 0.5667 - loss: 1.6272 - val_accuracy: 0.1131 - val_loss: 9.3461\n",
      "Epoch 20/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 63ms/step - accuracy: 0.5812 - loss: 1.5825 - val_accuracy: 0.1128 - val_loss: 9.5543\n",
      "Epoch 21/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 73ms/step - accuracy: 0.5789 - loss: 1.5998 - val_accuracy: 0.1156 - val_loss: 9.5534\n",
      "Epoch 22/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 74ms/step - accuracy: 0.5689 - loss: 1.6228 - val_accuracy: 0.1081 - val_loss: 9.7775\n",
      "Epoch 23/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 67ms/step - accuracy: 0.5821 - loss: 1.5783 - val_accuracy: 0.1188 - val_loss: 9.8719\n",
      "Epoch 24/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 70ms/step - accuracy: 0.5801 - loss: 1.5845 - val_accuracy: 0.1078 - val_loss: 9.9877\n",
      "Epoch 25/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 73ms/step - accuracy: 0.5901 - loss: 1.5482 - val_accuracy: 0.1118 - val_loss: 10.1612\n",
      "Epoch 26/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 64ms/step - accuracy: 0.5974 - loss: 1.5264 - val_accuracy: 0.1112 - val_loss: 10.2379\n",
      "Epoch 27/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 68ms/step - accuracy: 0.6004 - loss: 1.4976 - val_accuracy: 0.1150 - val_loss: 10.3980\n",
      "Epoch 28/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.5954 - loss: 1.4913 - val_accuracy: 0.1122 - val_loss: 10.5253\n",
      "Epoch 29/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 73ms/step - accuracy: 0.6088 - loss: 1.4614 - val_accuracy: 0.1068 - val_loss: 10.6963\n",
      "Epoch 30/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 63ms/step - accuracy: 0.6025 - loss: 1.4827 - val_accuracy: 0.1122 - val_loss: 10.7152\n",
      "Epoch 31/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 67ms/step - accuracy: 0.6069 - loss: 1.4711 - val_accuracy: 0.1040 - val_loss: 10.8272\n",
      "Epoch 32/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 66ms/step - accuracy: 0.5934 - loss: 1.4913 - val_accuracy: 0.1033 - val_loss: 10.9409\n",
      "Epoch 33/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 70ms/step - accuracy: 0.5978 - loss: 1.4805 - val_accuracy: 0.1078 - val_loss: 10.9388\n",
      "Epoch 34/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.6010 - loss: 1.4972 - val_accuracy: 0.1011 - val_loss: 11.0909\n",
      "Epoch 35/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 79ms/step - accuracy: 0.6148 - loss: 1.4291 - val_accuracy: 0.1021 - val_loss: 11.1439\n",
      "Epoch 36/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 66ms/step - accuracy: 0.5994 - loss: 1.4906 - val_accuracy: 0.1018 - val_loss: 11.1764\n",
      "Epoch 37/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 67ms/step - accuracy: 0.6128 - loss: 1.4568 - val_accuracy: 0.1049 - val_loss: 11.3269\n",
      "Epoch 38/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 70ms/step - accuracy: 0.6124 - loss: 1.4401 - val_accuracy: 0.1033 - val_loss: 11.4443\n",
      "Epoch 39/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 69ms/step - accuracy: 0.6023 - loss: 1.4906 - val_accuracy: 0.1055 - val_loss: 11.3913\n",
      "Epoch 40/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.6138 - loss: 1.4657 - val_accuracy: 0.1059 - val_loss: 11.5514\n",
      "Epoch 43/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 64ms/step - accuracy: 0.6173 - loss: 1.4222 - val_accuracy: 0.1049 - val_loss: 11.5924\n",
      "Epoch 44/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 75ms/step - accuracy: 0.6154 - loss: 1.4392 - val_accuracy: 0.1043 - val_loss: 11.7410\n",
      "Epoch 45/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 74ms/step - accuracy: 0.6154 - loss: 1.4228 - val_accuracy: 0.1059 - val_loss: 11.8127\n",
      "Epoch 46/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 73ms/step - accuracy: 0.6128 - loss: 1.4507 - val_accuracy: 0.1008 - val_loss: 11.8369\n",
      "Epoch 47/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.6144 - loss: 1.4467 - val_accuracy: 0.1002 - val_loss: 11.8628\n",
      "Epoch 48/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 69ms/step - accuracy: 0.6224 - loss: 1.4125 - val_accuracy: 0.1103 - val_loss: 11.9450\n",
      "Epoch 49/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 74ms/step - accuracy: 0.6075 - loss: 1.4815 - val_accuracy: 0.1024 - val_loss: 12.0265\n",
      "Epoch 50/50\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 81ms/step - accuracy: 0.5953 - loss: 1.5086 - val_accuracy: 0.1030 - val_loss: 11.9376\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100)) \n",
    "model.add(Bidirectional(LSTM(150)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "adam = Adam(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "history = model.fit(X_train_temp, y_train_temp, epochs=50, validation_data=(X_val, y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2321843-be36-40ba-8383-6007c39bd229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"lstm_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0e62626-f429-452a-a64a-eedc9eb1d685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "with open(\"lstm_model.json\", \"r\") as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6cde550-d9e4-4deb-9c0d-8dafbe402e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_top_five_words(model, tokenizer, seed_text):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict(token_list, verbose=0)\n",
    "    top_five_indexes = np.argsort(predicted[0])[::-1][:5]\n",
    "    top_five_words = []\n",
    "    for index in top_five_indexes:\n",
    "        for word, idx in tokenizer.word_index.items():\n",
    "            if idx == index:\n",
    "                top_five_words.append(word)\n",
    "                break\n",
    "    return top_five_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b391673e-e7b4-44c5-a2fa-77fcdc5d571b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['been', 'any', 'it', 'a', 'to']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seed_text = \"I have\"\n",
    "print(predict_top_five_words(model, tokenizer, seed_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b718bf5-8fc7-4394-9dc7-6b87a3fad0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no', 'the', 'mr', 'that', 'it']\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"what is\"\n",
    "print(predict_top_five_words(model, tokenizer, seed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1551341c-47bb-4406-8c85-898c459b95f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you', 'he', 'capable', 'we', 'no']\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"How are\"\n",
    "print(predict_top_five_words(model, tokenizer, seed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec834de-bd2f-4792-ba19-88da1a9d908d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe2747-0a8c-4fb4-8105-7b4e35bbbf82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
